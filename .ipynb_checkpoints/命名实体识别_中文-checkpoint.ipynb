{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70a58c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='hfl/rbt6', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3862, 7157, 3683, 6612, 1765, 4157, 1762, 1336, 7305,  680, 7032,\n",
       "         7305,  722, 7313, 4638, 3862, 1818,  511,  102,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0],\n",
       "        [ 101, 6821, 2429,  898, 2255,  988, 3717, 4638, 1300, 4289, 7667, 4507,\n",
       "         1744, 1079,  671, 3837, 4638, 6392, 6369, 2360,  712, 2898, 6392, 6369,\n",
       "         8024, 3146,  702, 2456, 5029, 5408, 5125, 5401, 5445, 2612, 2131,  511,\n",
       "          102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt6')\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#分词测试\n",
    "tokenizer.batch_encode_plus(\n",
    "    [[\n",
    "        '海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间',\n",
    "        '的', '海', '域', '。'\n",
    "    ],\n",
    "     [\n",
    "         '这', '座', '依', '山', '傍', '水', '的', '博', '物', '馆', '由', '国', '内', '一',\n",
    "         '流', '的', '设', '计', '师', '主', '持', '设', '计', '，', '整', '个', '建', '筑',\n",
    "         '群', '精', '美', '而', '恢', '宏', '。'\n",
    "     ]],\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='pt',\n",
    "    is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3362a434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20852,\n",
       " ['海',\n",
       "  '钓',\n",
       "  '比',\n",
       "  '赛',\n",
       "  '地',\n",
       "  '点',\n",
       "  '在',\n",
       "  '厦',\n",
       "  '门',\n",
       "  '与',\n",
       "  '金',\n",
       "  '门',\n",
       "  '之',\n",
       "  '间',\n",
       "  '的',\n",
       "  '海',\n",
       "  '域',\n",
       "  '。'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, split):\n",
    "        #names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "\n",
    "        #在线加载数据集\n",
    "        dataset = load_dataset(path='lansinuote/peoples-daily-ner',\n",
    "                               split=split)\n",
    "\n",
    "        #过滤掉太长的句子\n",
    "        def f(data):\n",
    "            return len(data['tokens']) <= 512 - 2\n",
    "\n",
    "        dataset = dataset.filter(f)\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        tokens = self.dataset[i]['tokens']\n",
    "        labels = self.dataset[i]['ner_tags']\n",
    "\n",
    "        return tokens, labels\n",
    "\n",
    "\n",
    "dataset = Dataset('train')\n",
    "\n",
    "tokens, labels = dataset[0]\n",
    "\n",
    "len(dataset), tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59695a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303\n",
      "[CLS] 国 家 银 行 主 要 通 过 对 货 币 投 放 量 和 利 息 率 的 控 制 ， 达 到 稳 定 本 国 货 币 、 增 加 外 汇 储 备 、 抑 制 通 货 膨 胀 的 目 的 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
      "input_ids torch.Size([16, 94])\n",
      "token_type_ids torch.Size([16, 94])\n",
      "attention_mask torch.Size([16, 94])\n"
     ]
    }
   ],
   "source": [
    "#数据整理函数\n",
    "def collate_fn(data):\n",
    "    tokens = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(tokens,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         is_split_into_words=True)\n",
    "\n",
    "    lens = inputs['input_ids'].shape[1]\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [7] + labels[i]\n",
    "        labels[i] += [7] * lens\n",
    "        labels[i] = labels[i][:lens]\n",
    "\n",
    "    return inputs, torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=16,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "#查看数据样例\n",
    "for i, (inputs, labels) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "print(len(loader))\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))\n",
    "print(labels[0])\n",
    "\n",
    "for k, v in inputs.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90b5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5974.0416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 94, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = AutoModel.from_pretrained('hfl/rbt6')\n",
    "pretrained.requires_grad_(False)\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in pretrained.parameters()) / 10000)\n",
    "\n",
    "#模型试算\n",
    "#[b, lens] -> [b, lens, 768]\n",
    "pretrained(**inputs).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3096c294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 94, 8])\n"
     ]
    }
   ],
   "source": [
    "#定义下游模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tuneing = False\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        self.rnn = torch.nn.GRU(768, 768, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.pretrained(**inputs).last_hidden_state\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.fc(out).softmax(dim=2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fine_tuneing(self, tuneing):\n",
    "        self.tuneing = tuneing\n",
    "        self.pretrained.requires_grad_(tuneing)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(model(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942184e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2455,  0.6611, -0.9850, -0.7210, -0.2470, -0.1299, -1.0160,  0.0246],\n",
       "         [ 1.0440,  2.8605,  1.2175,  0.5834,  0.1893,  0.4375,  0.6651, -0.7127],\n",
       "         [ 0.8248,  0.9940, -0.5361,  1.3210,  0.2208,  0.2666,  1.6294,  1.4698],\n",
       "         [ 0.4734,  1.0645,  1.2387, -0.4024,  0.6151, -1.4682, -0.2201, -1.8569],\n",
       "         [ 0.1573, -1.2819, -1.1607, -0.3261,  0.1492, -0.2599, -1.1425, -0.3315],\n",
       "         [-1.2250, -0.4709, -0.5910,  0.4635,  0.1000, -0.0412, -0.0479,  0.9608]]),\n",
       " tensor([1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对计算结果和label变形,并且移除pad\n",
    "def reshape_and_remove_pad(outs, labels, attention_mask):\n",
    "    #变形,便于计算loss\n",
    "    #[b, lens, 8] -> [b*lens, 8]\n",
    "    outs = outs.reshape(-1, 8)\n",
    "    #[b, lens] -> [b*lens]\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    #忽略对pad的计算结果\n",
    "    #[b, lens] -> [b*lens - pad]\n",
    "    select = attention_mask.reshape(-1) == 1\n",
    "    outs = outs[select]\n",
    "    labels = labels[select]\n",
    "\n",
    "    return outs, labels\n",
    "\n",
    "\n",
    "reshape_and_remove_pad(torch.randn(2, 3, 8), torch.ones(2, 3),\n",
    "                       torch.ones(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dab97e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16, 3, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取正确数量和总数\n",
    "def get_correct_and_total_count(labels, outs):\n",
    "    #[b*lens, 8] -> [b*lens]\n",
    "    outs = outs.argmax(dim=1)\n",
    "    correct = (outs == labels).sum().item()\n",
    "    total = len(labels)\n",
    "\n",
    "    #计算除了0以外元素的正确率,因为0太多了,包括的话,正确率很容易虚高\n",
    "    select = labels != 0\n",
    "    outs = outs[select]\n",
    "    labels = labels[select]\n",
    "    correct_content = (outs == labels).sum().item()\n",
    "    total_content = len(labels)\n",
    "\n",
    "    return correct, total, correct_content, total_content\n",
    "\n",
    "\n",
    "get_correct_and_total_count(torch.ones(16), torch.randn(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd44a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354.9704\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train(epochs):\n",
    "    lr = 2e-5 if model.tuneing else 5e-4\n",
    "\n",
    "    #训练\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, labels) in enumerate(loader):\n",
    "            #模型计算\n",
    "            #[b, lens] -> [b, lens, 8]\n",
    "            outs = model(inputs)\n",
    "\n",
    "            #对outs和label变形,并且移除pad\n",
    "            #outs -> [b, lens, 8] -> [c, 8]\n",
    "            #labels -> [b, lens] -> [c]\n",
    "            outs, labels = reshape_and_remove_pad(outs, labels,\n",
    "                                                  inputs['attention_mask'])\n",
    "\n",
    "            #梯度下降\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if step % 200 == 0:\n",
    "                counts = get_correct_and_total_count(labels, outs)\n",
    "\n",
    "                accuracy = counts[0] / counts[1]\n",
    "                accuracy_content = counts[2] / counts[3]\n",
    "\n",
    "                print(epoch, step, len(loader), loss.item(), accuracy,\n",
    "                      accuracy_content)\n",
    "\n",
    "        torch.save(model.state_dict(), 'model/命名实体识别_中文.model')\n",
    "\n",
    "\n",
    "model.fine_tuneing(False)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad) / 10000)\n",
    "#train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc02d6dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329.012\n"
     ]
    }
   ],
   "source": [
    "model.fine_tuneing(True)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad) / 10000)\n",
    "#train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622edfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.9903343782654127 0.9527783878761257\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model_load = Model()\n",
    "    model_load.load_state_dict(torch.load('model/命名实体识别_中文.model'))\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=128,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    correct_content = 0\n",
    "    total_content = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(loader_test):\n",
    "        if step == 5:\n",
    "            break\n",
    "        print(step)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #[b, lens] -> [b, lens, 8] -> [b, lens]\n",
    "            outs = model_load(inputs)\n",
    "\n",
    "        #对outs和label变形,并且移除pad\n",
    "        #outs -> [b, lens, 8] -> [c, 8]\n",
    "        #labels -> [b, lens] -> [c]\n",
    "        outs, labels = reshape_and_remove_pad(outs, labels,\n",
    "                                              inputs['attention_mask'])\n",
    "\n",
    "        counts = get_correct_and_total_count(labels, outs)\n",
    "        correct += counts[0]\n",
    "        total += counts[1]\n",
    "        correct_content += counts[2]\n",
    "        total_content += counts[3]\n",
    "\n",
    "    print(correct / total, correct_content / total_content)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fe8647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]此案经海口市中级人民法院一审，以受贿罪判处辛业江有期徒刑5年，依法追缴其非法所得。[SEP]\n",
      "[CLS]7···海3口4市4中4级4人4民4法4院4·········辛1业2江2·················[SEP]7\n",
      "[CLS]7···海5口4市4中4级4人4民4法4院4·········辛1业2江2·················[SEP]7\n",
      "==========================\n",
      "[CLS]谁知此水通天，不觉流进银河，而且直至宝光四射的斗牛宫。[SEP]\n",
      "[CLS]7···········银5河6··········斗5牛6宫6·[SEP]7\n",
      "[CLS]7·······················斗5牛6宫6·[SEP]7\n",
      "==========================\n",
      "[CLS][UNK]让世界少一点痛苦，为人间添一份幸福[UNK]。[SEP]\n",
      "[CLS]7····················[SEP]7\n",
      "[CLS]7····················[SEP]7\n",
      "==========================\n",
      "[CLS]这种经历使我得以较深刻地了解打工生活的甘苦。[SEP]\n",
      "[CLS]7······················[SEP]7\n",
      "[CLS]7······················[SEP]7\n",
      "==========================\n",
      "[CLS]1979年到1997年11月，欧盟对中国产品反倾销立案调查达71起，给中国出口造成很大损失。[SEP]\n",
      "[CLS]7···············欧3盟4·中5国6···············中5国6·········[SEP]7\n",
      "[CLS]7···············欧3盟4·中5国6···············中5国6·········[SEP]7\n",
      "==========================\n",
      "[CLS]在这一点上，高敏是经受考验、令人折服的。[SEP]\n",
      "[CLS]7······高1敏2············[SEP]7\n",
      "[CLS]7······高1敏2············[SEP]7\n",
      "==========================\n",
      "[CLS]美国电信管理部门、司法部门的官员对这起兼并反应谨慎。[SEP]\n",
      "[CLS]7美5国6························[SEP]7\n",
      "[CLS]7美5国6························[SEP]7\n",
      "==========================\n",
      "[CLS]四是不准出现村务不公开的村，确保100％的村实行财务公开、政策公开、政务公开，接受群众监督。[SEP]\n",
      "[CLS]7··············································[SEP]7\n",
      "[CLS]7··············································[SEP]7\n",
      "==========================\n",
      "[CLS]他们建立了书报刊市场经营者资格审查制、督察管理制、目标管理制，并率先推出『书报刊审读制度』，建立文化市场管理基金。[SEP]\n",
      "[CLS]7·························································[SEP]7\n",
      "[CLS]7·························································[SEP]7\n",
      "==========================\n",
      "[CLS]会议期间还将举办各种讨论会、展览会、文艺演出等活动，庆祝世界卫生组织成立50周年。[SEP]\n",
      "[CLS]7····························世3界4卫4生4组4织4·······[SEP]7\n",
      "[CLS]7····························世3界4卫4生4组4织4·······[SEP]7\n",
      "==========================\n",
      "[CLS]建立市场经济体制的前提是承认产权。[SEP]\n",
      "[CLS]7·················[SEP]7\n",
      "[CLS]7·················[SEP]7\n",
      "==========================\n",
      "[CLS]香港会在5到10年内发展成为以高增值产业为本的世界创新科技中心。[SEP]\n",
      "[CLS]7香5港6······························[SEP]7\n",
      "[CLS]7香5港6······························[SEP]7\n",
      "==========================\n",
      "[CLS]1997年全民义务植树25亿株，共人工造林421．2万公顷，飞播造林100万公顷，封山育林386．7万公顷。[SEP]\n",
      "[CLS]7······················································[SEP]7\n",
      "[CLS]7······················································[SEP]7\n",
      "==========================\n",
      "[CLS]1996年8月，这里骤降罕见暴雨，山洪肆虐，房倒屋塌，沙土流失，巨石滑坡，树木卷走，公路一处处破裂，桥梁一座座断折，水库储洪很快突破安全线。[SEP]\n",
      "[CLS]7······································································[SEP]7\n",
      "[CLS]7······································································[SEP]7\n",
      "==========================\n",
      "[CLS]由于经营有方，生意日益红火，这家饭店几乎天天顾客爆满，经营规模不断扩大，由一层楼变成了两层楼，又在市区内开了一家分店，为近百人解决了就业问题，但饭店从业人员中几乎没有一名一汽下岗职工和职工子弟，大部分都是外来的农民工。[SEP]\n",
      "[CLS]7·····················································································一3汽4······················[SEP]7\n",
      "[CLS]7·····················································································一3汽4······················[SEP]7\n",
      "==========================\n",
      "[CLS]这里的蔬菜为何夹杂在大田里种植呢？[SEP]\n",
      "[CLS]7·················[SEP]7\n",
      "[CLS]7·················[SEP]7\n",
      "==========================\n",
      "[CLS]其中单、双打的冠军将分别获得3000元和2000元的奖金。[SEP]\n",
      "[CLS]7·····························[SEP]7\n",
      "[CLS]7·····························[SEP]7\n",
      "==========================\n",
      "[CLS]他们身上未着任何雨具，一任雨淋风吹，队形不乱，笑颜不改。[SEP]\n",
      "[CLS]7····························[SEP]7\n",
      "[CLS]7····························[SEP]7\n",
      "==========================\n",
      "[CLS]姆贝基说，[UNK]由于国家重建与民族和解未能取得预期效果，种族和经济状况仍然把南非分为黑白两种社会。[UNK][SEP]\n",
      "[CLS]7姆1贝2基2·································南5非6··········[SEP]7\n",
      "[CLS]7姆1贝2基2·································南5非6··········[SEP]7\n",
      "==========================\n",
      "[CLS]自今年4月初以来，费尔南德斯多次攻击中国，声称中国是印度的[UNK]头号威胁[UNK]，无中生有地说中国在缅甸建立针对印度的电子监听设施。[SEP]\n",
      "[CLS]7·········费1尔2南2德2斯2····中5国6···中5国6·印5度6··············中5国6·缅5甸6····印5度6········[SEP]7\n",
      "[CLS]7·········费5尔6南6德6斯6····中5国6···中5国6·印5度6··············中5国6·缅5甸6····印5度6········[SEP]7\n",
      "==========================\n",
      "[CLS]联合国维和五十年－－－访米亚特副秘书长[SEP]\n",
      "[CLS]7联3合4国4·········米1亚2特2····[SEP]7\n",
      "[CLS]7联3合4国4·········米5亚6特6····[SEP]7\n",
      "==========================\n",
      "[CLS]50年后，今年5月23日，董存瑞的家乡河北省怀来县举办一系列活动告慰英灵。[SEP]\n",
      "[CLS]7·············董1存2瑞2···河5北6省6怀5来6县6············[SEP]7\n",
      "[CLS]7·············董1存2瑞2···河5北6省6怀5来6县6············[SEP]7\n",
      "==========================\n",
      "[CLS]在上届世锦赛上，奥登西亚和保拉组成的核心对子，配合默契，投篮准确，在半决赛中淘汰了夺冠呼声很高的美国队，并在决赛中战胜中国队。[SEP]\n",
      "[CLS]7········奥1登2西2亚2·保1拉2·································美3国4队4········中3国4队4·[SEP]7\n",
      "[CLS]7········奥1登2西2亚2·保1拉2·································美3国4队4········中3国4队4·[SEP]7\n",
      "==========================\n",
      "[CLS]其目的就是保证在对中国、丹麦、韩国、马来西亚等强队时在第四场稳取一分。[SEP]\n",
      "[CLS]7·········中3国4·丹3麦4·韩3国4·马3来4西4亚4·············[SEP]7\n",
      "[CLS]7·········中3国4·丹3麦4·韩5国4·马5来6西6亚6·············[SEP]7\n",
      "==========================\n",
      "[CLS]问：当前经济活动中的担保还有哪些问题值得注意？[SEP]\n",
      "[CLS]7·······················[SEP]7\n",
      "[CLS]7·······················[SEP]7\n",
      "==========================\n",
      "[CLS]这个外部环境优劣与否，关键在于项目建设单位的领导者。[SEP]\n",
      "[CLS]7··························[SEP]7\n",
      "[CLS]7··························[SEP]7\n",
      "==========================\n",
      "[CLS]长航集团所属长江轮船海外旅游总公司，是长江上最大的旅游企业，拥有15条豪华旅游船，能提供水陆联运、地面接待等一条龙旅游服务。[SEP]\n",
      "[CLS]7长3航4集4团4··长3江4轮4船4海4外4旅4游4总4公4司4··长5江6·········································[SEP]7\n",
      "[CLS]7长3航4集4团4··长3江4轮4船4海4外4旅4游4总4公4司4··长5江6·········································[SEP]7\n",
      "==========================\n",
      "[CLS]如果全国的农田基本建设都能这样做，就不知可以避免多少浪费，少走多少弯路，少受多少损失！[SEP]\n",
      "[CLS]7···········································[SEP]7\n",
      "[CLS]7···········································[SEP]7\n",
      "==========================\n",
      "[CLS]中、斯联合登山队将认真总结第一次攀登失利的经验，根据队员的身体状况，伺机进行第二次突击顶峰。[SEP]\n",
      "[CLS]7中3、4斯4联4合4登4山4队4······································[SEP]7\n",
      "[CLS]7中3·斯3联4合4登4山4队4······································[SEP]7\n",
      "==========================\n",
      "[CLS]80年代以来，中国又成为毒品过境的受害国，由于中国毗邻毒源地之一[UNK]金三角[UNK]的特定地理位置，国际贩毒集团把中国作为贩运毒品的重要通道。[SEP]\n",
      "[CLS]7·······中5国6··············中5国6········金5三6角6················中5国6············[SEP]7\n",
      "[CLS]7·······中5国6··············中5国6····················国3际4贩4毒4集4团4·中5国6············[SEP]7\n",
      "==========================\n",
      "[CLS]他说，韩国人进球后，我们垮了，有些失控。[SEP]\n",
      "[CLS]7···韩5国6···············[SEP]7\n",
      "[CLS]7···韩5国6···············[SEP]7\n",
      "==========================\n",
      "[CLS]本报纽约4月13日电记者周德武报道：今天，美国第三大银行国民银行和第四大银行美洲银行宣布合并，合并金额达648亿美元，其资产总值超过5700亿美元，抢走了美国第一大银行的桂冠。[SEP]\n",
      "[CLS]7··纽5约6········周1德2武2······美5国6·····国3民4银4行4······美3洲4银4行4···································美5国6·········[SEP]7\n",
      "[CLS]7··纽5约6········周1德2武2······美5国6·····国3民4银4行4······美3洲4银4行4···································美5国6·········[SEP]7\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def predict():\n",
    "    model_load = Model()\n",
    "    model_load.load_state_dict(torch.load('model/命名实体识别_中文.model'))\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #[b, lens] -> [b, lens, 8] -> [b, lens]\n",
    "        outs = model_load(inputs).argmax(dim=2)\n",
    "\n",
    "    for i in range(32):\n",
    "        #移除pad\n",
    "        select = inputs['attention_mask'][i] == 1\n",
    "        input_id = inputs['input_ids'][i, select]\n",
    "        out = outs[i, select]\n",
    "        label = labels[i, select]\n",
    "\n",
    "        #输出原句子\n",
    "        print(tokenizer.decode(input_id).replace(' ', ''))\n",
    "\n",
    "        #输出tag\n",
    "        for tag in [label, out]:\n",
    "            s = ''\n",
    "            for j in range(len(tag)):\n",
    "                if tag[j] == 0:\n",
    "                    s += '·'\n",
    "                    continue\n",
    "                s += tokenizer.decode(input_id[j])\n",
    "                s += str(tag[j].item())\n",
    "\n",
    "            print(s)\n",
    "        print('==========================')\n",
    "\n",
    "\n",
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
